---
title: "R_learner_Essai_4_Causal_Forest"
author: "K.S"
date: "2025-04-29"
output: html_document
---

```{r}
evaluate_model_grf <- function(model, Y_true, threshold = 0.5) {
  # Vérifie le type de modèle
  model_class <- class(model)[1]
  
  
  
  if (model_class == "regression_forest") {
    # Régression continue
    # Prédictions
    Y_pred <- predict(model)$predictions
    mse <- mean((Y_true - Y_pred)^2)
    mae <- mean(abs(Y_true - Y_pred))
    r2 <- 1 - sum((Y_true - Y_pred)^2) / sum((Y_true - mean(Y_true))^2)
    
    return(list(
      type = "regression",
      MSE = mse,
      MAE = mae,
      R2 = r2
    ))
    
  } else if (model_class == "probability_forest") {
    # Probabilités (binaire)
    # Y_pred are probabilities
    # Prédictions
    Y_pred <- predict(model)$predictions[,"1"]
    log_loss <- -mean(Y_true * log(Y_pred + 1e-15) + (1 - Y_true) * log(1 - Y_pred + 1e-15))
    Y_class <- ifelse(Y_pred >= threshold, 1, 0)
    accuracy <- mean(Y_class == Y_true)
    
    # AUC avec pROC
    if (requireNamespace("pROC", quietly = TRUE)) {
      auc <- pROC::roc(Y_true, Y_pred)$auc
    } else {
      auc <- NA
      warning("Le package 'pROC' est requis pour calculer l'AUC. Installe-le avec install.packages('pROC').")
    }
    
    return(list(
      type = "binary (probability)",
      LogLoss = log_loss,
      Accuracy = accuracy,
      AUC = auc
    ))
    
  } else if (model_class == "classification_forest") {
    # Classification directe (0/1)
    accuracy <- mean(Y_pred == Y_true)
    
    return(list(
      type = "binary (classification)",
      Accuracy = accuracy
    ))
    
  } else {
    stop("Type de modèle non reconnu.")
  }
}

```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(haven)
path<- c("C:/Users/steph/Documents/ENSAE/Projet statapp/code perso/essai R")
setwd(path)
df <-read_dta("bt_analysis_final.dta")
```

```{r}
x_basic <- c("B_Sgender_index2", "B_Sage_cat", "B_Sgrade6", "B_Sclass_rank_high", "B_Sgirl", "B_Shh_size", 
"B_no_female_sib", "B_no_male_sib", "B_Solder_sister",  "B_Sradio_house",          

"B_rural","B_Sdistrict", "B_Scaste",
  
"B_Sown_house",  "B_q10_guest_teachr", "B_fulltime_teacher", "B_pct_female_teacher",
  "B_Spart_extracurr", "B_Smonitor_sch", "B_Soften_bunk", "B_coed",

  "Cfem_lit_rate", "Cmale_lit_rate", "Cfem_lab_part" , "Sschool_id"
)
```

```{r}
#install.packages("grf")
library(grf)
```

```{r}
df1 <- df[-which(is.na(df$E_Sgender_index2)),]
Y=as.vector(df1$E_Sgender_index2)
Z = df1[x_basic]
X = df1[x_basic]
D= as.vector(df1$B_treat)
Sschool_id = as.numeric(df1$Sschool_id)
```

```{r}
Y.forest = regression_forest(X,Y,clusters=Sschool_id,equalize.cluster.weights = TRUE)
Y.hat.forest = predict(Y.forest)$predictions
D.forest = probability_forest(X,as.factor(D),clusters=Sschool_id,equalize.cluster.weights = TRUE)
D.hat.forest = predict(D.forest)$predictions[,"1"] #on ne garde que les proba d'être 1

#tracer le propensity score en fonction de quelques caractéristiques

cf.raw = causal_forest(X,Y,D, Y.hat = Y.hat.forest, W.hat = D.hat.forest, clusters = Sschool_id, equalize.cluster.weights = TRUE,tune.parameters = "all")

```

```{r}
evaluate_model_grf(Y.forest,Y)
evaluate_model_grf(D.forest,D)
```

```{r}
##vraiment pertinent?
var_imp = variable_importance(cf.raw)
selected.idx = which(var_imp > mean(var_imp))
var_imp_selected = x_basic[selected.idx]
var_imp_selected
```
```{r}
#cf = causal_forest(X[,selected.idx], Y, D,
#                   Y.hat = Y.hat.forest, W.hat = D.hat.forest,
#                  clusters = school.id,
#                   equalize.cluster.weights = TRUE,
#                   tune.parameters = "all")
cf<-cf.raw
```


```{r}
tau.hat.forest = predict(cf)$predictions
mean(tau.hat.forest) #mean à 0.181 presque exactement l'effet du papier.
```

# histogram of CATE
```{r}
hist(tau.hat.forest,main="Histogram of estimate CATE")
```


#estimation de l'ATE

```{r}

ATE = average_treatment_effect(cf)
paste("95% CI for the ATE:", round(ATE[1], 3),
      "+/-", round(qnorm(0.975) * ATE[2], 3)) #effet de traitement positif
```

# Assessing heterogeneity

## methode 1 : low and high CATE groups
```{r}
high_effect = tau.hat.forest > median(tau.hat.forest)
ate.high =  average_treatment_effect(cf,subset = high_effect)
ate.low = average_treatment_effect(cf,subset = !high_effect)
paste("95% CI for difference in ATE:",
      round(ate.high[1] - ate.low[1], 3), "+/-",
      round(qnorm(0.975) * sqrt(ate.high[2]^2 + ate.low[2]^2), 3))
# 0 appartient àl'intervalle de confiance donc pas de signe flagrant d'heterogénéité globale.
```
## methode 2 : best linear predictor analysis

```{r}
test_calibration(cf) 
### coefficient Di non significatif --pas d'hétérogénéité individuelle détectée
```
# Heterogeneity across variables








