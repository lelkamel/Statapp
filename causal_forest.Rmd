---
title: "R_learner_Essai_4_Causal_Forest"
author: "K.S"
date: "2025-04-29"
output: html_document
---

```{r}
evaluate_model_grf <- function(model, Y_true, threshold = 0.5) {
  # Vérifie le type de modèle
  model_class <- class(model)[1]
  
  
  
  if (model_class == "regression_forest") {
    # Régression continue
    # Prédictions
    Y_pred <- predict(model)$predictions
    mse <- mean((Y_true - Y_pred)^2)
    mae <- mean(abs(Y_true - Y_pred))
    r2 <- 1 - sum((Y_true - Y_pred)^2) / sum((Y_true - mean(Y_true))^2)
    
    return(list(
      type = "regression",
      MSE = mse,
      MAE = mae,
      R2 = r2
    ))
    
  } else if (model_class == "probability_forest") {
    # Probabilités (binaire)
    # Y_pred are probabilities
    # Prédictions
    Y_pred <- predict(model)$predictions[,"1"]
    log_loss <- -mean(Y_true * log(Y_pred + 1e-15) + (1 - Y_true) * log(1 - Y_pred + 1e-15))
    Y_class <- ifelse(Y_pred >= threshold, 1, 0)
    accuracy <- mean(Y_class == Y_true)
    
    # AUC avec pROC
    if (requireNamespace("pROC", quietly = TRUE)) {
      auc <- pROC::roc(Y_true, Y_pred)$auc
    } else {
      auc <- NA
      warning("Le package 'pROC' est requis pour calculer l'AUC. Installe-le avec install.packages('pROC').")
    }
    
    return(list(
      type = "binary (probability)",
      LogLoss = log_loss,
      Accuracy = accuracy,
      AUC = auc
    ))
    
  } else if (model_class == "classification_forest") {
    # Classification directe (0/1)
    accuracy <- mean(Y_pred == Y_true)
    
    return(list(
      type = "binary (classification)",
      Accuracy = accuracy
    ))
    
  } else {
    stop("Type de modèle non reconnu.")
  }
}

```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(haven)
```


```{r}
#Accès Stéphane
path<- c("C:/Users/steph/Documents/ENSAE/Projet statapp/code perso/essai R")
setwd(path)
df <-read_dta("bt_analysis_final.dta")
```

```{r}
#Accès Lyna
data_path = 'C:/Users/lynae/OneDrive - GENES/Bureau/ENSAE/statapp/Base de donnée/Main Analysis and Paper/Analysis data' 
df <- read_dta(paste0(data_path, "/bt_analysis_final.dta"))
```


```{r}
x_basic <- c("B_Sgender_index2", "B_Sage_cat", "B_Sgrade6", "B_Sclass_rank_high", "B_Sgirl", "B_Shh_size", 
"B_no_female_sib", "B_no_male_sib", "B_Solder_sister",  "B_Sradio_house",          

"B_rural","B_Sdistrict", "B_Scaste",
  
"B_Sown_house",  "B_q10_guest_teachr", "B_fulltime_teacher", "B_pct_female_teacher",
  "B_Spart_extracurr", "B_Smonitor_sch", "B_Soften_bunk", "B_coed",

  "Cfem_lit_rate", "Cmale_lit_rate", "Cfem_lab_part" , "Sschool_id"
)
```

```{r}
#install.packages("grf")
library(grf)
```

```{r}
df1 <- df[-which(is.na(df$E_Sgender_index2)),]
Y=as.vector(df1$E_Sgender_index2)
Z = df1[x_basic]
X = df1[x_basic]
D= as.vector(df1$B_treat)
Sschool_id = as.numeric(df1$Sschool_id)
```

# Estimation de e* et m*

```{r}
#On commence par estimer e* et m* grâce aux forêts
Y.forest = regression_forest(X,Y,clusters=Sschool_id,equalize.cluster.weights = TRUE)
Y.hat.forest = predict(Y.forest)$predictions
D.forest = probability_forest(X,as.factor(D),clusters=Sschool_id,equalize.cluster.weights = TRUE)
D.hat.forest = predict(D.forest)$predictions[,"1"] #on ne garde que les proba d'être 1
#tracer le propensity score en fonction de quelques caractéristiques
```

```{r}
evaluate_model_grf(Y.forest,Y)
evaluate_model_grf(D.forest,D)
```

# Entraînement des modèles
##Modèle de forêt causale prenant en compte les clusters et toutes les variables X


```{r}
#On entraîne le modèle de forêt causale en injectant le Y.hat et le W.hat calculé auparavant
cf.raw = causal_forest(X,Y,D, Y.hat = Y.hat.forest, W.hat = D.hat.forest, clusters = Sschool_id, equalize.cluster.weights = TRUE,tune.parameters = "all")

```


```{r}
##Quelles sont les variables qui ont le plus de poids dans l'hétérogénéité?
var_imp = variable_importance(cf.raw)
selected.idx = which(var_imp > mean(var_imp))
var_imp_selected = x_basic[selected.idx]
var_imp_selected
```


```{r}
cf<-cf.raw
```

```{r}
#Estimation du CATE
tau.hat.forest = predict(cf)$predictions
mean(tau.hat.forest) #mean à 0.181 presque exactement l'effet du papier.
```



## Modèle de forêt causale prenant en compte les clusters et uniquement les X ayant le + de poids
```{r}
#Modèle ne retenant que les variables ayant le + de poids
cf_var_imp = causal_forest(X[,selected.idx], Y, D,
                   Y.hat = Y.hat.forest, W.hat = D.hat.forest,
                  clusters = Sschool_id,
                   equalize.cluster.weights = TRUE,
                   tune.parameters = "all")
```

```{r}
tau.hat.forest.var.imp = predict(cf_var_imp)$predictions
mean(tau.hat.forest.var.imp) #On retrouve l'effet moyen du papier également, quoiqu'on est plus proche qu'avec le premier modèle
```

# histogram of CATE
```{r}
#Modèle avec tous les X
hist(tau.hat.forest,main="Histogram of estimate CATE")
```

```{r}
#Histogramme, pour le modèle ne retenant que les variables importantes
hist(tau.hat.forest.var.imp,main="Histogram of estimate CATE in the reduced model")
```

#estimation de l'ATE

```{r}
#Significativité statistique de l'ATE du modèle 1
ATE = average_treatment_effect(cf)
paste("95% CI for the ATE:", round(ATE[1], 3),
      "+/-", round(qnorm(0.975) * ATE[2], 3)) #effet de traitement positif
```

```{r}
#Significativité statistique de l'ATE du modèle 2
ATE = average_treatment_effect(cf_var_imp)
paste("95% CI for the ATE:", round(ATE[1], 3),
      "+/-", round(qnorm(0.975) * ATE[2], 3))
```


# Assessing heterogeneity

## methode 1 : low and high CATE groups
```{r}
high_effect = tau.hat.forest > median(tau.hat.forest)
ate.high =  average_treatment_effect(cf,subset = high_effect)
ate.low = average_treatment_effect(cf,subset = !high_effect)
paste("95% CI for difference in ATE:",
      round(ate.high[1] - ate.low[1], 3), "+/-",
      round(qnorm(0.975) * sqrt(ate.high[2]^2 + ate.low[2]^2), 3))
# 0 appartient àl'intervalle de confiance donc pas de signe flagrant d'heterogénéité globale.
```
## methode 2 : best linear predictor analysis

```{r}
test_calibration(cf) 
### coefficient Di non significatif --pas d'hétérogénéité individuelle détectée
```


# Heterogeneity across variables

Vraie question : à partir de quel taux de variation juge-t-on que l'on a une hétérogénéité pertinente à explorer ? 

```{r}
#Modèle parcimonieux : variable Cfem_lit_rate
pardef = par(mar = c(5, 4, 4, 2) + 0.5, cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
boxplot(tau.hat.forest.var.imp~ cut(X$Cfem_lit_rate, breaks=10), 
        xlab = "Cfem_lit_rate (découpé en 10 groupes)", 
        ylab = "estimated CATE")
lines(smooth.spline(X$Cfem_lit_rate, tau.hat.forest.var.imp, df = 4), lwd = 2, col = 4)

#Y a pas l'air d'y avoir une hétérogénéité folle, après mes catégories sont complètement arbitraires ..
```

```{r}
#Modèle parcimonieux : variable B_pct_female_teacher
pardef = par(mar = c(5, 4, 4, 2) + 0.5, cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
boxplot(tau.hat.forest.var.imp ~ cut(X$Cfem_lit_rate, breaks=10), xlab = "B_pct_female_teacher (découpé en 10 groupes)", ylab = "estimated CATE")
lines(smooth.spline(X$B_pct_female_teacher, tau.hat.forest.var.imp, df = 4), lwd = 2, col = 4)

#De l'hétérogénéité t'as peur... Mais encore une fois des outliers.
```

```{r}
#Modèle parcimonieux : variable B_fulltime_teacher
pardef = par(mar = c(5, 4, 4, 2) + 0.5, cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
boxplot(tau.hat.forest.var.imp ~ cut(X$B_fulltime_teacher, breaks=20), xlab = "Sschool_id (découpé en 20)", ylab = "estimated CATE")
lines(smooth.spline(X$B_fulltime_teacher, tau.hat.forest.var.imp, df = 4), lwd = 2, col = 4)

Comment conclure ?
```

## Exploration + fine de l'hétérogénéité
```{r}
#Je prends un sous-groupe qui affiche pas mal d'outlier et je creuse la q°
subgroup <- which(X$Cfem_lit_rate >= 0.52 & X$Cfem_lit_rate <= 0.55)
summary(tau.hat.forest.var.imp[subgroup])
boxplot(tau.hat.forest.var.imp[subgroup], main = "CATE for 0.52 <= Cfem_lit_rate <= 0.55")

# Pour voir les variables associées à ces observations
summary(X[subgroup, ])
```

Remarque : T'as quand même une grande hétérogénéité au sein de cette sous-catégorie (cf. les résultats de summary(tau.hat.forest.var.imp[subgroup])). Je pense que ça vaudrait le coup d'avoir une analyse en faisceau, i.e. de voir l'effet hétérogène pour un vecteur x donné (ce que nous permet a priori le modèle, nan ?)








